{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 50.040 Natural Language Processing (Fall 2024) Homework 3\n",
    "\n",
    "**Due 29 November 2024, 23:59 PM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### STUDENT ID: 1006184\n",
    "\n",
    "### Name: Atul Parida\n",
    "\n",
    "### Students with whom you have discussed (if any):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: d2l in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (1.0.3)\n",
      "Requirement already satisfied: jupyter==1.0.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from d2l) (1.0.0)\n",
      "Requirement already satisfied: numpy==1.23.5 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from d2l) (1.23.5)\n",
      "Requirement already satisfied: matplotlib==3.7.2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from d2l) (3.7.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from d2l) (0.1.6)\n",
      "Requirement already satisfied: requests==2.31.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from d2l) (2.31.0)\n",
      "Requirement already satisfied: pandas==2.0.3 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from d2l) (2.0.3)\n",
      "Requirement already satisfied: scipy==1.10.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from d2l) (1.10.1)\n",
      "Requirement already satisfied: notebook in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter==1.0.0->d2l) (7.2.2)\n",
      "Requirement already satisfied: qtconsole in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
      "Requirement already satisfied: jupyter-console in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter==1.0.0->d2l) (6.6.3)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter==1.0.0->d2l) (7.16.4)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter==1.0.0->d2l) (6.29.5)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter==1.0.0->d2l) (8.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (24.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (10.4.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (2.9.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib==3.7.2->d2l) (6.4.5)\n",
      "Requirement already satisfied: traitlets in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from matplotlib-inline==0.1.6->d2l) (5.14.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from pandas==2.0.3->d2l) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from pandas==2.0.3->d2l) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests==2.31.0->d2l) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests==2.31.0->d2l) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests==2.31.0->d2l) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from requests==2.31.0->d2l) (2024.8.30)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib==3.7.2->d2l) (3.20.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib==3.7.2->d2l) (1.16.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (1.6.7)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (8.12.2)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (7.4.9)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (5.7.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (5.9.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (24.0.1)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipykernel->jupyter==1.0.0->d2l) (6.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipywidgets->jupyter==1.0.0->d2l) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.0.13)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.30 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-console->jupyter==1.0.0->d2l) (3.0.43)\n",
      "Requirement already satisfied: pygments in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-console->jupyter==1.0.0->d2l) (2.15.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (4.12.3)\n",
      "Requirement already satisfied: bleach!=5.0.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (6.1.0)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (8.5.0)\n",
      "Requirement already satisfied: jinja2>=3.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (3.1.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3.0)\n",
      "Requirement already satisfied: markupsafe>=2.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (2.1.3)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (3.0.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (0.10.0)\n",
      "Requirement already satisfied: nbformat>=5.7 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (5.10.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbconvert->jupyter==1.0.0->d2l) (1.4.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=2.4.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from notebook->jupyter==1.0.0->d2l) (2.14.2)\n",
      "Requirement already satisfied: jupyterlab-server<3,>=2.27.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from notebook->jupyter==1.0.0->d2l) (2.27.3)\n",
      "Requirement already satisfied: jupyterlab<4.3,>=4.2.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from notebook->jupyter==1.0.0->d2l) (4.2.5)\n",
      "Requirement already satisfied: notebook-shim<0.3,>=0.2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from notebook->jupyter==1.0.0->d2l) (0.2.4)\n",
      "Requirement already satisfied: qtpy>=2.4.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from qtconsole->jupyter==1.0.0->d2l) (2.4.2)\n",
      "Requirement already satisfied: webencodings in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from bleach!=5.0.0->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.19.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
      "Requirement already satisfied: stack-data in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.4.6)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter==1.0.0->d2l) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\atulp\\appdata\\roaming\\python\\python38\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.0.0->d2l) (2.5.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->jupyter==1.0.0->d2l) (305.1)\n",
      "Requirement already satisfied: anyio>=3.1.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (4.3.0)\n",
      "Requirement already satisfied: argon2-cffi>=21.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (21.1.0)\n",
      "Requirement already satisfied: jupyter-events>=0.9.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (0.10.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (0.5.3)\n",
      "Requirement already satisfied: overrides>=5.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (7.7.0)\n",
      "Requirement already satisfied: prometheus-client>=0.9 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (0.21.0)\n",
      "Requirement already satisfied: pywinpty>=2.0.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (2.0.10)\n",
      "Requirement already satisfied: send2trash>=1.8.2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (0.18.1)\n",
      "Requirement already satisfied: websocket-client>=1.7 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
      "Requirement already satisfied: async-lru>=1.0.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter==1.0.0->d2l) (2.0.4)\n",
      "Requirement already satisfied: httpx>=0.25.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter==1.0.0->d2l) (0.27.2)\n",
      "Requirement already satisfied: jupyter-lsp>=2.0.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter==1.0.0->d2l) (2.2.5)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter==1.0.0->d2l) (75.1.0)\n",
      "Requirement already satisfied: tomli>=1.2.2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab<4.3,>=4.2.0->notebook->jupyter==1.0.0->d2l) (2.0.2)\n",
      "Requirement already satisfied: babel>=2.10 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (2.14.0)\n",
      "Requirement already satisfied: json5>=0.9.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (0.9.25)\n",
      "Requirement already satisfied: jsonschema>=4.18.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (4.23.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from nbformat>=5.7->nbconvert->jupyter==1.0.0->d2l) (2.20.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from prompt-toolkit>=3.0.30->jupyter-console->jupyter==1.0.0->d2l) (0.2.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from beautifulsoup4->nbconvert->jupyter==1.0.0->d2l) (2.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.2.2)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.17.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter==1.0.0->d2l) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab<4.3,>=4.2.0->notebook->jupyter==1.0.0->d2l) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (2024.10.1)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (1.3.10)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->notebook->jupyter==1.0.0->d2l) (0.10.6)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (2.0.7)\n",
      "Requirement already satisfied: pyyaml>=5.3 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (6.0)\n",
      "Requirement already satisfied: rfc3339-validator in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (0.1.1)\n",
      "Requirement already satisfied: executing in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter==1.0.0->d2l) (0.2.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (2.22)\n",
      "Requirement already satisfied: fqdn in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.5.1)\n",
      "Requirement already satisfied: isoduration in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (3.0.0)\n",
      "Requirement already satisfied: uri-template in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (24.8.0)\n",
      "Requirement already satisfied: arrow>=0.15.0 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in c:\\users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->notebook->jupyter==1.0.0->d2l) (2.9.0.20241003)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install d2l\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous deep learning methods use architectures like multilayer perceptron, convolutional network, and recurrent network. In recent years, Transformer-based models are the leading approach for nearly all natural language processing tasks. The Transformer model is built on the attention mechanism, which was initially designed as an improvement for encoder-decoder RNNs in sequence-to-sequence tasks like machine translation. In this homework, we will begin with the attention mechanism and gradually progress to understanding Transformers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Mechanisms\n",
    "\n",
    "Consider the following: denote by $\\mathcal{D} = \\{(\\mathbf{k}_1, \\mathbf{v}_1), \\ldots, (\\mathbf{k}_m, \\mathbf{v}_m)\\}$ a database of $m$ tuples of *keys* and *values*. Moreover, denote by $\\mathbf{q}$ a *query*. Then we can define the *attention* over $\\mathcal{D}$ as\n",
    "\n",
    "$$\n",
    "\\text{Attention}(\\mathbf{q}, \\mathcal{D}) = \\sum_{i=1}^{m} \\alpha(\\mathbf{q}, \\mathbf{k}_i) \\mathbf{v}_i\n",
    "$$\n",
    "\n",
    "where $\\alpha(\\mathbf{q}, \\mathbf{k}_i) \\in \\mathcal{R}$ $(i = 1, \\ldots, m)$ are scalar attention weights. This operation is commonly known as *attention pooling*. The term *attention* reflects the mechanism’s ability to focus on specific elements in the dataset, assigning higher weights $\\alpha$ to the terms in $\\mathcal{D}$ that are deemed more relevant or significant. Consequently, the attention mechanism produces a weighted linear combination of the values in the database, emphasizing the most important components.\n",
    "\n",
    "A common strategy for ensuring that the weights sum up to 1 is to normalize them via\n",
    "\n",
    "$$\n",
    "\\alpha(\\mathbf{q}, \\mathbf{k}_i) = \\frac{\\alpha(\\mathbf{q}, \\mathbf{k}_i)}{\\sum_j \\alpha(\\mathbf{q}, \\mathbf{k}_j)}.\n",
    "$$\n",
    "\n",
    "In particular, to ensure that the weights are also nonnegative, one can resort to exponentiation. This means that we can now pick any function $a(\\mathbf{q}, \\mathbf{k})$ and then apply the softmax operation used for multinomial models to it via\n",
    "\n",
    "$$\n",
    "\\alpha(\\mathbf{q}, \\mathbf{k}_i) = \\frac{\\exp(a(\\mathbf{q}, \\mathbf{k}_i))}{\\sum_j \\exp(a(\\mathbf{q}, \\mathbf{k}_j))}.\n",
    "$$\n",
    "\n",
    "Then, we need to keep the order of magnitude of the arguments in the exponential function under control. Assume that all the elements of the query $\\mathbf{q} \\in \\mathcal{R}^d$ and the key $\\mathbf{k}_i \\in \\mathcal{R}^d$ are independent and identically drawn random variables with zero mean and unit variance. The dot product between both vectors has zero mean and a variance of $d$. To ensure that the variance of the dot product still remains 1 regardless of vector length, we use the *scaled dot product attention* scoring function. That is, we rescale the dot product by $1/\\sqrt{d}$. We thus arrive at the first commonly used attention function that is used:\n",
    "\n",
    "$$\n",
    "a(\\mathbf{q}, \\mathbf{k}_i) = \\frac{\\mathbf{q}^\\top \\mathbf{k}_i}{\\sqrt{d}}.\n",
    "$$\n",
    "\n",
    "Note that attention weights $\\alpha$ still need normalizing. We can simplify this further via the softmax operation:\n",
    "\n",
    "$$\n",
    "\\alpha(\\mathbf{q}, \\mathbf{k}_i) = \\text{softmax}(a(\\mathbf{q}, \\mathbf{k}_i)) = \\frac{\\exp(\\mathbf{q}^\\top \\mathbf{k}_i / \\sqrt{d})}{\\sum_{j=1}^m \\exp(\\mathbf{q}^\\top \\mathbf{k}_j / \\sqrt{d})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 [code] (5 points)\n",
    "One of the most popular applications of the attention mechanism is to sequence models. For example, assume that we have the following three sentences with different length:\n",
    "\n",
    "| Study | about | Deep    | Learning  |\n",
    "|-------|-------|---------|-----------|\n",
    "| Start | by    | code    | `<blank>` |\n",
    "| Hello | world | `<blank>` | `<blank>` |\n",
    "\n",
    "Implement the function ``masked_softmax`` that deals with sequences of different lengths. Then, run the sanity check cell to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masked_softmax(X, valid_lens):  #@save\n",
    "    \"\"\"Perform softmax operation by masking elements on the last axis.\"\"\"\n",
    "    # X: 3D tensor, valid_lens: 1D or 2D tensor\n",
    "    def _sequence_mask(X, valid_len, value=0):\n",
    "        maxlen = X.size(1)\n",
    "        mask = torch.arange((maxlen), dtype=torch.float32,\n",
    "                            device=X.device)[None, :] < valid_len[:, None]\n",
    "        X[~mask] = value\n",
    "        return X\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    # Hint: On the last axis, replace masked elements with a very large negative value, whose exponentiation outputs 0\n",
    "    if valid_lens.dim() == 1:\n",
    "        valid_lens = valid_lens.repeat(X.shape[1])\n",
    "    else:\n",
    "        valid_lens = valid_lens.reshape(-1)\n",
    "    shape = X.shape\n",
    "    ### END OF YOUR CODE\n",
    "    return nn.functional.softmax(X.reshape(shape), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3086, 0.2441, 0.2017, 0.2455],\n",
       "         [0.2703, 0.1696, 0.1754, 0.3848]],\n",
       "\n",
       "        [[0.2493, 0.2589, 0.3158, 0.1760],\n",
       "         [0.2233, 0.1733, 0.2717, 0.3317]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "masked_softmax(torch.rand(2, 2, 4), torch.tensor([2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2 (9 points)\n",
    "In practice, we often think of minibatches for efficiency, such as computing attention for $n$ queries and $m$ key-value pairs, where queries and keys are of length $d$ and values are of length $v$. The scaled dot product attention of queries $\\mathbf{Q} \\in \\mathcal{R}^{n \\times d}$, keys $\\mathbf{K} \\in \\mathcal{R}^{m \\times d}$, and values $\\mathbf{V} \\in \\mathcal{R}^{m \\times v}$ thus can be written as\n",
    "\n",
    "$$\n",
    "\\text{softmax} \\left( \\frac{\\mathbf{Q}\\mathbf{K}^\\top}{\\sqrt{d}} \\right) \\mathbf{V} \\in \\mathcal{R}^{n \\times v}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.1 [written] (4 points)** Write the shape of queries, keys and values during the calculation of scaled dot product attention. You should fill in the shape inside the code box.\n",
    "\n",
    "**Question 2.2 [code] (5 points)** Implement function ``DotProductAttention`` that calculates the scaled dot product attention. Then, run the sanity check cell to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductAttention(nn.Module):  #@save\n",
    "    \"\"\"Scaled dot product attention.\"\"\"\n",
    "    def __init__(self, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    # Shape of queries: \n",
    "    # Shape of keys: \n",
    "    # Shape of values: \n",
    "    # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)\n",
    "    def forward(self, queries, keys, values, valid_lens=None):\n",
    "        ### YOUR CODE HERE\n",
    "        d = queries.shape[-1]\n",
    "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
    "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
    "        ### END OF YOUR CODE\n",
    "        return torch.bmm(self.dropout(self.attention_weights), values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass!\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "queries = torch.normal(0, 1, (2, 1, 2))\n",
    "keys = torch.normal(0, 1, (2, 10, 2))\n",
    "values = torch.normal(0, 1, (2, 10, 4))\n",
    "valid_lens = torch.tensor([2, 6])\n",
    "\n",
    "attention = DotProductAttention(dropout=0.5)\n",
    "attention.eval()\n",
    "d2l.check_shape(attention(queries, keys, values, valid_lens), (2, 1, 4))\n",
    "print(\"Pass!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"187.07675pt\" height=\"97.56pt\" viewBox=\"0 0 187.07675 97.56\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2024-11-16T18:10:27.236244</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 97.56 \n",
       "L 187.07675 97.56 \n",
       "L 187.07675 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 34.240625 59.94 \n",
       "L 145.840625 59.94 \n",
       "L 145.840625 37.62 \n",
       "L 34.240625 37.62 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p803a744c05)\">\n",
       "    <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAJsAAAAfCAYAAADwQL9CAAAA5ElEQVR4nO3UQQpBYRSG4fP/XcnMQDFibAWGsgJlFzZkL8oWyIwypWSgW9RN6f7W4Jz6Ru8z/zqTt5O++20xr3ftnpqZ2afxb7u90Ok8mbq37eUYum05+bf1M3Z7MPJvH7fQ6RxaA38gNsgQG2SIDTLEBhligwyxQYbYIENskCE2yBAbZIgNMsQGGWKDDLFBprLTwT3Oi1XoeOoP3dvSvEK3rbT+7f0aOp3nS/d2PZ6Fbm/OO/e2VJ3QbT4bZIgNMsQGGWKDDLFBhtggQ2yQITbIEBtkiA0yxAYZYoMMsUGG2CDzA6/VHAhd9+rsAAAAAElFTkSuQmCC\" id=\"image7fa9a7a05e\" transform=\"scale(1 -1) translate(0 -22.32)\" x=\"34.240625\" y=\"-37.62\" width=\"111.6\" height=\"22.32\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path id=\"ma467b0f72c\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma467b0f72c\" x=\"39.820625\" y=\"59.94\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(36.639375 74.538438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#ma467b0f72c\" x=\"95.620625\" y=\"59.94\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(92.439375 74.538438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_3\">\n",
       "     <!-- Keys -->\n",
       "     <g transform=\"translate(78.371094 88.216563) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-4b\" d=\"M 628 4666 \n",
       "L 1259 4666 \n",
       "L 1259 2694 \n",
       "L 3353 4666 \n",
       "L 4166 4666 \n",
       "L 1850 2491 \n",
       "L 4331 0 \n",
       "L 3500 0 \n",
       "L 1259 2247 \n",
       "L 1259 0 \n",
       "L 628 0 \n",
       "L 628 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \n",
       "L 3597 1613 \n",
       "L 953 1613 \n",
       "Q 991 1019 1311 708 \n",
       "Q 1631 397 2203 397 \n",
       "Q 2534 397 2845 478 \n",
       "Q 3156 559 3463 722 \n",
       "L 3463 178 \n",
       "Q 3153 47 2828 -22 \n",
       "Q 2503 -91 2169 -91 \n",
       "Q 1331 -91 842 396 \n",
       "Q 353 884 353 1716 \n",
       "Q 353 2575 817 3079 \n",
       "Q 1281 3584 2069 3584 \n",
       "Q 2775 3584 3186 3129 \n",
       "Q 3597 2675 3597 1894 \n",
       "z\n",
       "M 3022 2063 \n",
       "Q 3016 2534 2758 2815 \n",
       "Q 2500 3097 2075 3097 \n",
       "Q 1594 3097 1305 2825 \n",
       "Q 1016 2553 972 2059 \n",
       "L 3022 2063 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \n",
       "Q 1816 -950 1584 -1140 \n",
       "Q 1353 -1331 966 -1331 \n",
       "L 506 -1331 \n",
       "L 506 -850 \n",
       "L 844 -850 \n",
       "Q 1081 -850 1212 -737 \n",
       "Q 1344 -625 1503 -206 \n",
       "L 1606 56 \n",
       "L 191 3500 \n",
       "L 800 3500 \n",
       "L 1894 763 \n",
       "L 2988 3500 \n",
       "L 3597 3500 \n",
       "L 2059 -325 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \n",
       "L 2834 2853 \n",
       "Q 2591 2978 2328 3040 \n",
       "Q 2066 3103 1784 3103 \n",
       "Q 1356 3103 1142 2972 \n",
       "Q 928 2841 928 2578 \n",
       "Q 928 2378 1081 2264 \n",
       "Q 1234 2150 1697 2047 \n",
       "L 1894 2003 \n",
       "Q 2506 1872 2764 1633 \n",
       "Q 3022 1394 3022 966 \n",
       "Q 3022 478 2636 193 \n",
       "Q 2250 -91 1575 -91 \n",
       "Q 1294 -91 989 -36 \n",
       "Q 684 19 347 128 \n",
       "L 347 722 \n",
       "Q 666 556 975 473 \n",
       "Q 1284 391 1588 391 \n",
       "Q 1994 391 2212 530 \n",
       "Q 2431 669 2431 922 \n",
       "Q 2431 1156 2273 1281 \n",
       "Q 2116 1406 1581 1522 \n",
       "L 1381 1569 \n",
       "Q 847 1681 609 1914 \n",
       "Q 372 2147 372 2553 \n",
       "Q 372 3047 722 3315 \n",
       "Q 1072 3584 1716 3584 \n",
       "Q 2034 3584 2315 3537 \n",
       "Q 2597 3491 2834 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-4b\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"60.576172\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-79\" x=\"122.099609\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"181.279297\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <defs>\n",
       "       <path id=\"md4b57a2530\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#md4b57a2530\" x=\"34.240625\" y=\"43.2\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 0 -->\n",
       "      <g transform=\"translate(20.878125 46.999219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#md4b57a2530\" x=\"34.240625\" y=\"54.36\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(20.878125 58.159219) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_6\">\n",
       "     <!-- Queries -->\n",
       "     <g transform=\"translate(14.798437 68.087031) rotate(-90) scale(0.1 -0.1)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-51\" d=\"M 2522 4238 \n",
       "Q 1834 4238 1429 3725 \n",
       "Q 1025 3213 1025 2328 \n",
       "Q 1025 1447 1429 934 \n",
       "Q 1834 422 2522 422 \n",
       "Q 3209 422 3611 934 \n",
       "Q 4013 1447 4013 2328 \n",
       "Q 4013 3213 3611 3725 \n",
       "Q 3209 4238 2522 4238 \n",
       "z\n",
       "M 3406 84 \n",
       "L 4238 -825 \n",
       "L 3475 -825 \n",
       "L 2784 -78 \n",
       "Q 2681 -84 2626 -87 \n",
       "Q 2572 -91 2522 -91 \n",
       "Q 1538 -91 948 567 \n",
       "Q 359 1225 359 2328 \n",
       "Q 359 3434 948 4092 \n",
       "Q 1538 4750 2522 4750 \n",
       "Q 3503 4750 4090 4092 \n",
       "Q 4678 3434 4678 2328 \n",
       "Q 4678 1516 4351 937 \n",
       "Q 4025 359 3406 84 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \n",
       "L 544 3500 \n",
       "L 1119 3500 \n",
       "L 1119 1403 \n",
       "Q 1119 906 1312 657 \n",
       "Q 1506 409 1894 409 \n",
       "Q 2359 409 2629 706 \n",
       "Q 2900 1003 2900 1516 \n",
       "L 2900 3500 \n",
       "L 3475 3500 \n",
       "L 3475 0 \n",
       "L 2900 0 \n",
       "L 2900 538 \n",
       "Q 2691 219 2414 64 \n",
       "Q 2138 -91 1772 -91 \n",
       "Q 1169 -91 856 284 \n",
       "Q 544 659 544 1381 \n",
       "z\n",
       "M 1991 3584 \n",
       "L 1991 3584 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \n",
       "Q 2534 3019 2420 3045 \n",
       "Q 2306 3072 2169 3072 \n",
       "Q 1681 3072 1420 2755 \n",
       "Q 1159 2438 1159 1844 \n",
       "L 1159 0 \n",
       "L 581 0 \n",
       "L 581 3500 \n",
       "L 1159 3500 \n",
       "L 1159 2956 \n",
       "Q 1341 3275 1631 3429 \n",
       "Q 1922 3584 2338 3584 \n",
       "Q 2397 3584 2469 3576 \n",
       "Q 2541 3569 2628 3553 \n",
       "L 2631 2963 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \n",
       "L 1178 3500 \n",
       "L 1178 0 \n",
       "L 603 0 \n",
       "L 603 3500 \n",
       "z\n",
       "M 603 4863 \n",
       "L 1178 4863 \n",
       "L 1178 4134 \n",
       "L 603 4134 \n",
       "L 603 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-51\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-75\" x=\"78.710938\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"142.089844\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-72\" x=\"203.613281\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-69\" x=\"244.726562\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-65\" x=\"272.509766\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-73\" x=\"334.033203\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 34.240625 59.94 \n",
       "L 34.240625 37.62 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 145.840625 59.94 \n",
       "L 145.840625 37.62 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 34.240625 59.94 \n",
       "L 145.840625 59.94 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 34.240625 37.62 \n",
       "L 145.840625 37.62 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 152.815625 90.36 \n",
       "L 156.973625 90.36 \n",
       "L 156.973625 7.2 \n",
       "L 152.815625 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <image xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAAAYAAABzCAYAAAC7I3M6AAAAvElEQVR4nNWWQQ7DIBADtxL//2ovPYX1bj/AILmijZojK3tsQlAe/Xp2LJ4RXav13aBQsUTEiJLJaGZgKpexsaIePhwHchWd8z54iOBk1QdT2fAPGJnHrP4NjueKTjvDSYEFfStb0b+A+wOMK4STYtI3iIpz8Jp2XH+QbkGOK7jbiy59kZVIsWEs1zfwxB42HOPK3hKfAcVjJP0zFA7ISqSAtDEUCHcZ9xYkxYXvnApi3CTFxQrXylfM7zPe0QYMUq8gR84AAAAASUVORK5CYII=\" id=\"imagee7c876c0aa\" transform=\"scale(1 -1) translate(0 -82.8)\" x=\"152.64\" y=\"-7.2\" width=\"4.32\" height=\"82.8\"/>\n",
       "   <g id=\"matplotlib.axis_3\"/>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <defs>\n",
       "       <path id=\"m3e335ed60b\" d=\"M 0 0 \n",
       "L 3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3e335ed60b\" x=\"156.973625\" y=\"70.986891\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 0.1 -->\n",
       "      <g transform=\"translate(163.973625 74.78611) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3e335ed60b\" x=\"156.973625\" y=\"49.274279\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.2 -->\n",
       "      <g transform=\"translate(163.973625 53.073497) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3e335ed60b\" x=\"156.973625\" y=\"27.561666\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.3 -->\n",
       "      <g transform=\"translate(163.973625 31.360885) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \n",
       "Q 3050 2419 3304 2112 \n",
       "Q 3559 1806 3559 1356 \n",
       "Q 3559 666 3084 287 \n",
       "Q 2609 -91 1734 -91 \n",
       "Q 1441 -91 1130 -33 \n",
       "Q 819 25 488 141 \n",
       "L 488 750 \n",
       "Q 750 597 1062 519 \n",
       "Q 1375 441 1716 441 \n",
       "Q 2309 441 2620 675 \n",
       "Q 2931 909 2931 1356 \n",
       "Q 2931 1769 2642 2001 \n",
       "Q 2353 2234 1838 2234 \n",
       "L 1294 2234 \n",
       "L 1294 2753 \n",
       "L 1863 2753 \n",
       "Q 2328 2753 2575 2939 \n",
       "Q 2822 3125 2822 3475 \n",
       "Q 2822 3834 2567 4026 \n",
       "Q 2313 4219 1838 4219 \n",
       "Q 1578 4219 1281 4162 \n",
       "Q 984 4106 628 3988 \n",
       "L 628 4550 \n",
       "Q 988 4650 1302 4700 \n",
       "Q 1616 4750 1894 4750 \n",
       "Q 2613 4750 3031 4423 \n",
       "Q 3450 4097 3450 3541 \n",
       "Q 3450 3153 3228 2886 \n",
       "Q 3006 2619 2597 2516 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"LineCollection_1\"/>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 152.815625 90.36 \n",
       "L 154.894625 90.36 \n",
       "L 156.973625 90.36 \n",
       "L 156.973625 7.2 \n",
       "L 154.894625 7.2 \n",
       "L 152.815625 7.2 \n",
       "L 152.815625 90.36 \n",
       "z\n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p803a744c05\">\n",
       "   <rect x=\"34.240625\" y=\"37.62\" width=\"111.6\" height=\"22.32\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 250x250 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d2l.show_heatmaps(attention.attention_weights.reshape((1, 1, 2, 10)),\n",
    "                  xlabel='Keys', ylabel='Queries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Seq2Seq\n",
    "Attention mechanisms can be effectively integrated into encoder-decoder architectures for sequence-to-sequence learning. Traditionally, in an RNN-based approach, all relevant information from the source sequence is encoded into a fixed-dimensional state representation by the encoder. However, rather than maintaining this state—represented by the context variable $\\mathbf{c}$ that summarizes the source sentence—as a fixed value, it can be dynamically updated. This update is based on both the original text (encoder hidden states $\\mathbf{h}_{t}$) and the previously generated text (decoder hidden states $\\mathbf{s}_{t’-1}$). As a result, we obtain an updated context variable $\\mathbf{c}_{t’}$ after each decoding time step $t’$. This approach allows the model to adapt the context dynamically, even for input sequences of length $T$, thereby improving the ability to handle long-range dependencies and capture more nuanced information from the source sequence.\n",
    "In this case, the context variable is the output of attention pooling:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{c}_{t'} = \\sum_{t=1}^{T} \\alpha(\\mathbf{s}_{t'-1}, \\mathbf{h}_t) \\mathbf{h}_t.\n",
    "\\end{equation}\n",
    "\n",
    "We used $\\mathbf{s}_{t'-1}$ as the query, and $\\mathbf{h}_t$ as both the key and the value. Note that $\\mathbf{c}_{t'}$ is then used to generate the state $\\mathbf{s}_{t'}$ and to generate a new token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3 [code] (6 points)\n",
    "Implement the RNN decoder in the ``Seq2SeqAttentionDecoder`` class. The decoder’s state is initialized using three components: \n",
    "\n",
    "(i) the hidden states of the encoder’s last layer across all time steps, which are utilized as keys and values for the attention mechanism; \n",
    "\n",
    "(ii) the hidden state of the encoder’s final time step at all layers, which initializes the decoder’s hidden state; and \n",
    "\n",
    "(iii) the valid length of the encoder to exclude padding tokens during attention pooling. During each decoding time step, the hidden state of the decoder’s final layer from the previous step is used as the query for the attention mechanism. The attention mechanism’s output is then concatenated with the input embedding to form the input for the RNN decoder, effectively guiding the generation process with context from both the source sequence and previous decoder outputs.\n",
    "\n",
    "Then, run the sanity check cell to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(d2l.Decoder):  #@save\n",
    "    \"\"\"The base attention-based decoder interface.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqAttentionDecoder(AttentionDecoder):\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0):\n",
    "        super().__init__()\n",
    "        self.attention = d2l.AdditiveAttention(num_hiddens, dropout)\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = nn.GRU(\n",
    "            embed_size + num_hiddens, num_hiddens, num_layers,\n",
    "            dropout=dropout)\n",
    "        self.dense = nn.LazyLinear(vocab_size)\n",
    "        self.apply(d2l.init_seq2seq)\n",
    "\n",
    "    def init_state(self, enc_outputs, enc_valid_lens):\n",
    "        # Shape of outputs: (num_steps, batch_size, num_hiddens).\n",
    "        # Shape of hidden_state: (num_layers, batch_size, num_hiddens)\n",
    "        outputs, hidden_state = enc_outputs\n",
    "        return (outputs.permute(1, 0, 2), hidden_state, enc_valid_lens)\n",
    "\n",
    "    def forward(self, X, state):\n",
    "        # Shape of enc_outputs: (batch_size, num_steps, num_hiddens).\n",
    "        # Shape of hidden_state: (num_layers, batch_size, num_hiddens)\n",
    "        enc_outputs, hidden_state, enc_valid_lens = state\n",
    "        # Shape of the output X: (num_steps, batch_size, embed_size)\n",
    "        X = self.embedding(X).permute(1, 0, 2)\n",
    "        outputs, self._attention_weights = [], []\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        for x in X:\n",
    "            query = torch.unsqueeze(hidden_state[-1], dim=1)\n",
    "            context = self.attention(query, enc_outputs, enc_outputs,\n",
    "                                     enc_valid_lens)\n",
    "            x = torch.cat((torch.squeeze(context, dim=1), torch.squeeze(x, dim=1)), dim=1)\n",
    "            out, hidden_state = self.rnn(x.unsqueeze(0), hidden_state)\n",
    "            outputs.append(out)\n",
    "            self._attention_weights.append(self.attention.attention_weights)\n",
    "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
    "\n",
    "        ### END OF YOUR CODE\n",
    "        return outputs.permute(1, 0, 2), [enc_outputs, hidden_state,\n",
    "                                          enc_valid_lens]\n",
    "\n",
    "    @property\n",
    "    def attention_weights(self):\n",
    "        return self._attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass!\n"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "vocab_size, embed_size, num_hiddens, num_layers = 10, 8, 16, 2\n",
    "batch_size, num_steps = 4, 7\n",
    "encoder = d2l.Seq2SeqEncoder(vocab_size, embed_size, num_hiddens, num_layers)\n",
    "decoder = Seq2SeqAttentionDecoder(vocab_size, embed_size, num_hiddens,\n",
    "                                  num_layers)\n",
    "X = torch.zeros((batch_size, num_steps), dtype=torch.long)\n",
    "state = decoder.init_state(encoder(X), None)\n",
    "output, state = decoder(X, state)\n",
    "d2l.check_shape(output, (batch_size, num_steps, vocab_size))\n",
    "d2l.check_shape(state[0], (batch_size, num_steps, num_hiddens))\n",
    "d2l.check_shape(state[1][0], (batch_size, num_hiddens))\n",
    "print(\"Pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multihead Attention\n",
    "Rather than relying on a single attention pooling operation, the queries, keys, and values can be transformed through $h$ independently learned linear projections. These $h$ projected queries, keys, and values are then processed in parallel through attention pooling. Afterward, the $h$ resulting attention outputs, known as ``heads``, are concatenated and passed through another learned linear projection to generate the final output. This architecture, referred to as ``multi-head attention``, allows each attention head to focus on different parts of the input, enabling the model to capture a wider range of information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Multihead attention](Multihead_attention.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a query $\\mathbf{q} \\in \\mathcal{R}^{d_q}$, a key $\\mathbf{k} \\in \\mathcal{R}^{d_k}$, and a value $\\mathbf{v} \\in \\mathcal{R}^{d_v}$, each attention head $\\mathbf{h}_i$ $(i = 1, \\ldots, h)$ is computed as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{h}_i = f(\\mathbf{W}_i^{(q)} \\mathbf{q}, \\mathbf{W}_i^{(k)} \\mathbf{k}, \\mathbf{W}_i^{(v)} \\mathbf{v}) \\in \\mathcal{R}^{p_v},\n",
    "\\end{equation}\n",
    "\n",
    "where $\\mathbf{W}_i^{(q)} \\in \\mathcal{R}^{p_q \\times d_q}$, $\\mathbf{W}_i^{(k)} \\in \\mathcal{R}^{p_k \\times d_k}$, and $\\mathbf{W}_i^{(v)} \\in \\mathcal{R}^{p_v \\times d_v}$ are learnable parameters and $f$ is attention pooling. The multi-head attention output is another linear transformation via learnable parameters $\\mathbf{W}_o \\in \\mathcal{R}^{p_o \\times hp_v}$ of the concatenation of $h$ heads:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{W}_o \n",
    "\\begin{bmatrix}\n",
    "\\mathbf{h}_1 \\\\\n",
    "\\vdots \\\\\n",
    "\\mathbf{h}_h\n",
    "\\end{bmatrix}\n",
    "\\in \\mathcal{R}^{p_o}. \n",
    "\\end{equation}\n",
    "\n",
    "Based on this design, each head may attend to different parts of the input. More sophisticated functions than the simple weighted average can be expressed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4 [written] (4 points)\n",
    "Please describe the benefits of using multi-head attention instead of single head attention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your answer here**\n",
    "\n",
    "In practice, given the same set of queries, keys, and values we may want our model to combine knowledge from different behaviors of the same attention mechanism, such as capturing dependencies of various ranges (e.g., shorter-range vs. longer-range) within a sequence. Thus, it may be beneficial to allow our attention mechanism to jointly use different representation subspaces of queries, keys, and values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5 [code] (12 points)\n",
    "In this implementation, we choose the scaled dot product attention for each head of the multi-head attention. To avoid significant growth of computational cost and parameterization cost, we set $p_q = p_k = p_v = p_o / h$. Note that $h$ heads can be computed in parallel if we set the number of outputs of linear transformations for the query, key, and value to $p_qh = p_kh = p_vh = p_o$. In the following implementation, $p_o$ is specified via the argument ``num_hiddens``.\n",
    "\n",
    "\n",
    "To allow for parallel computation of multiple heads, the ``MultiHeadAttention`` class uses two transposition methods ``transpose_output`` and ``transpose_output``. Specifically, the ``transpose_output`` method reverses the operation of the ``transpose_qkv`` method.\n",
    "\n",
    "**Question 5.1 [code] (4 points)** Implement function ``transpose_qkv``, which is the transposition for parallel computation of multiple attention heads.\n",
    "\n",
    "**Question 5.2 [code] (4 points)** Implement function ``transpose_output`` that reverse the operation of ``transpose_qkv``.\n",
    "\n",
    "**Question 5.3 [code] (4 points)**\n",
    "Complete `MultiHeadAttention` class. (Hint: you can use the two function you defined in question 5.1 and 5.2 .)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(d2l.Module):  #@save\n",
    "    \"\"\"Multi-head attention.\"\"\"\n",
    "    def __init__(self, num_hiddens, num_heads, dropout, bias=False, **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = d2l.DotProductAttention(dropout)\n",
    "        self.W_q = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "        self.W_k = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "        self.W_v = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "        self.W_o = nn.LazyLinear(num_hiddens, bias=bias)\n",
    "\n",
    "    def forward(self, queries, keys, values, valid_lens):\n",
    "        # Shape of queries, keys, or values:\n",
    "        # (batch_size, no. of queries or key-value pairs, num_hiddens)\n",
    "        # Shape of valid_lens: (batch_size,) or (batch_size, no. of queries)\n",
    "        # After transposing, shape of output queries, keys, or values:\n",
    "        # (batch_size * num_heads, no. of queries or key-value pairs,\n",
    "        # num_hiddens / num_heads)\n",
    "        \n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "        ### END OF YOUR CODE\n",
    "        return self.W_o(output_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(MultiHeadAttention)  #@save\n",
    "def transpose_qkv(self, X):\n",
    "    \"\"\"Transposition for parallel computation of multiple attention heads.\"\"\"\n",
    "    # Shape of input X: (batch_size, no. of queries or key-value pairs,\n",
    "    # num_hiddens). Shape of output X: (batch_size, no. of queries or\n",
    "    # key-value pairs, num_heads, num_hiddens / num_heads)\n",
    "\n",
    "    ### YOUR CODE HERE\n",
    "    for i in range(self.num_heads):\n",
    "        X[i] = self.W_q(X[i])\n",
    "        X[i] = self.W_k(X[i])\n",
    "        X[i] = self.W_v(X[i])\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "    return \n",
    "\n",
    "@d2l.add_to_class(MultiHeadAttention)  #@save\n",
    "def transpose_output(self, X):\n",
    "    \"\"\"Reverse the operation of transpose_qkv.\"\"\"\n",
    "    \n",
    "    ### YOUR CODE HERE\n",
    "    for i in range(self.num_heads):\n",
    "        X[i] = self.W_o(X[i])\n",
    "\n",
    "    ### END OF YOUR CODE\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m X \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, num_queries, num_hiddens))\n\u001b[0;32m      7\u001b[0m Y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, num_kvpairs, num_hiddens))\n\u001b[1;32m----> 8\u001b[0m d2l\u001b[38;5;241m.\u001b[39mcheck_shape(\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_lens\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m      9\u001b[0m                 (batch_size, num_queries, num_hiddens))\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPass!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\atulp\\anaconda3\\envs\\testenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[0;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[0;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[0;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "Cell \u001b[1;32mIn[31], line 22\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[1;34m(self, queries, keys, values, valid_lens)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, queries, keys, values, valid_lens):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# Shape of queries, keys, or values:\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# (batch_size, no. of queries or key-value pairs, num_hiddens)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m### YOUR CODE HERE\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# Project and transpose queries, keys, and values\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m     queries \u001b[38;5;241m=\u001b[39m \u001b[43mtranspose_qkv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_q\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     keys \u001b[38;5;241m=\u001b[39m transpose_qkv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_k(keys), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n\u001b[0;32m     24\u001b[0m     values \u001b[38;5;241m=\u001b[39m transpose_qkv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_v(values), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "# sanity check\n",
    "num_hiddens, num_heads = 100, 5\n",
    "attention = MultiHeadAttention(num_hiddens, num_heads, 0.5)\n",
    "batch_size, num_queries, num_kvpairs = 2, 4, 6\n",
    "valid_lens = torch.tensor([3, 2])\n",
    "X = torch.ones((batch_size, num_queries, num_hiddens))\n",
    "Y = torch.ones((batch_size, num_kvpairs, num_hiddens))\n",
    "d2l.check_shape(attention(X, Y, Y, valid_lens),\n",
    "                (batch_size, num_queries, num_hiddens))\n",
    "print(\"Pass!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention and Positional Encoding\n",
    "In self-attention, the queries, keys, and values are represented as $n \\times d$ matrices, where $n$ is the sequence length and $d$ is the feature dimension. The scaled dot-product attention operates by first multiplying an $n \\times d$ query matrix by a $d \\times n$ key matrix, producing an $n \\times n$ output. This output is then multiplied by an $n \\times d$ value matrix, resulting in another $n \\times d$ matrix. Consequently, the self-attention mechanism has a computational complexity of $\\mathcal{O}(n^2 d)$. Since each token can attend to every other token in the sequence, self-attention provides direct connections between all tokens, enabling parallel computation with $\\mathcal{O}(1)$ sequential operations and a maximum path length of $\\mathcal{O}(1)$. However, the quadratic complexity with respect to the sequence length ($n^2$) makes self-attention computationally expensive and impractical for very long sequences, significantly slowing down processing in such cases.\n",
    "\n",
    "Unlike RNNs, which process tokens sequentially, self-attention eliminates the need for sequential operations by leveraging parallel computation. However, self-attention alone does not inherently capture the order of tokens in a sequence. So, what happens when the order of the input matters? The standard solution is to introduce \\textit{positional encodings}—additional information associated with each token to indicate its position in the sequence. These positional encodings can either be learned during training or predefined in advance. By incorporating this positional information, the model gains awareness of the token order, allowing it to preserve sequence structure while benefiting from the parallelism of self-attention.\n",
    "\n",
    "Suppose that the input representation $\\mathbf{X} \\in \\mathcal{R}^{n \\times d}$ contains the $d$-dimensional embeddings for $n$ tokens of a sequence. The positional encoding outputs $\\mathbf{X} + \\mathbf{P}$ using a positional embedding matrix $\\mathbf{P} \\in \\mathcal{R}^{n \\times d}$ of the same shape, whose element on the $i^{\\text{th}}$ row and the $(2j)^{\\text{th}}$ or the $(2j+1)^{\\text{th}}$ column is\n",
    "\n",
    "\\begin{equation}\n",
    "p_{i, 2j} = \\sin \\left( \\frac{i}{10000^{2j/d}} \\right), \\quad\n",
    "p_{i, 2j+1} = \\cos \\left( \\frac{i}{10000^{2j/d}} \\right).\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6 [code] (4 points)\n",
    "Implement the ``PositionalEncoding`` class. Then, run the sanity check cell to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):  #@save\n",
    "    \"\"\"Positional encoding.\"\"\"\n",
    "    def __init__(self, num_hiddens, dropout, max_len=1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        # Create a long enough P\n",
    "        ### YOUR CODE HERE\n",
    "        self.P = torch.zeros((1, max_len, num_hiddens))\n",
    "        X = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1) / torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "        self.P[:, :, 0::2] = torch.sin(X)\n",
    "        self.P[:, :, 1::2] = torch.cos(X)\n",
    "\n",
    "        ### END OF YOUR CODE\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = X + self.P[:, :X.shape[1], :].to(X.device)\n",
    "        return self.dropout(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "encoding_dim, num_steps = 32, 60\n",
    "pos_encoding = PositionalEncoding(encoding_dim, 0)\n",
    "X = pos_encoding(torch.zeros((1, num_steps, encoding_dim)))\n",
    "P = pos_encoding.P[:, :X.shape[1], :]\n",
    "d2l.plot(torch.arange(num_steps), P[0, :, 6:10].T, xlabel='Row (position)',\n",
    "         figsize=(6, 2.5), legend=[\"Col %d\" % d for d in torch.arange(6, 10)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
